# ğŸ“Š E-Commerce Price Analysis & Web Scraping
## ğŸ“Œ Project Overview
This project automates the **scraping, cleaning, and analysis of product prices** from multiple e-commerce platforms (**eBay, Flipkart, and Reliance Digital**). The goal is to compare prices for **laptops, smartphones, and tablets**, identify trends, and visualize pricing differences.
## ğŸ›  Features
âœ… **Multi-threaded Web Scraping**: Extracts product data from multiple websites in parallel.  
âœ… **Data Cleaning & Standardization**: Converts prices to USD, removes duplicates, and formats model names.  
âœ… **Price Analysis & Visualization**: Generates histograms, bar charts, and line charts to explore pricing trends. 
## ğŸ“‚ Project Structure
```
ğŸ“¦ project-root
 â”£ ğŸ“‚ data                  # Raw scraped data
 â”£ ğŸ“‚ cache                  # Stores visited URLs if the data scraping process was interrupted 
 â”£ ğŸ“‚ cleaned_data           # Processed & cleaned datasets
 â”£ ğŸ“‚ scraping_scripts       # Web scraping scripts
 â”£ ğŸ“‚ visualization          # Jupyter notebooks for analysis
 â”£ ğŸ“‚ logs                   # Error logs
 â”£ ğŸ“‚ cleaning_data_script   # Cleans & standardizes scraped data
 â”£ ğŸ“œ main.py                # Runs all scrapers in parallel
 â”£ ğŸ“œ requirements.txt       # Dependencies
 â”£ ğŸ“œ README.md              # Project documentation
 â”£ ğŸ“œ .env.example           # Example configuration for environment variables
 â”£ ğŸ“œ .env                   # Configuration file for environment variables (to be created)
```
## ğŸš€ Installation & Setup
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-repo-url.git
cd project-root
```

### 2ï¸âƒ£ Create a Virtual Environment & Activate It
#### On Windows
```bash
python -m venv venv
venv\Scripts\activate
```
#### On macOS/Linux
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Up the `.env` File
Before running the scraper, you need to configure the `.env` file with your proxy credentials. This project uses environment variables for sensitive information such as proxy settings.

1. Copy the `.env.example` file to create a new `.env` file:
   ```bash
   cp .env.example .env
   ```

2. Open the `.env` file in a text editor and update the values with your actual proxy credentials:
   ```
   # Proxy for eBay
   ROTATING_PROXY_DOMAINE_NAME_EBAY=your_rotating_proxy_domain_for_ebay_scraping
   ROTATING_PROXY_PORT_EBAY=your_rotating_proxy_port_for_ebay_scraping
   ROTATING_PROXY_USERNAME_EBAY=your_rotating_proxy_username_for_ebay_scraping
   ROTATING_PROXY_PASSWORD_EBAY=your_rotating_proxy_password_for_ebay_scraping

   # Proxy for Reliance Digital
   PROXY_USERNAME_RELIANCE_DIGITAL=your_proxy_username_for_reliance_digital_scraping
   PROXY_PASSWORD_RELIANCE_DIGITAL=your_proxy_password_for_reliance_digital_scraping

   # A list of proxies to be used when scraping Reliance Digital
   PROXY_LIST=proxy1:port1,proxy2:port2,proxy3:port3
   ```

   Replace the placeholder values (`your_*`) with your actual proxy credentials.

### 5ï¸âƒ£ Run the Scraper
Once the `.env` file is configured, you can start the scraping process:
```bash
python main.py
```
This will start scraping data from eBay, Flipkart, and Reliance Digital simultaneously.

### 6ï¸âƒ£ Clean & Process Data
After the scraping is complete, clean and standardize the data:
```bash
python ./cleaning_data_scripts/cleaning_data_script.py
```
This script converts currency, removes duplicates, and standardizes model names.

### 7ï¸âƒ£ Run Analysis & Visualization
Open the Jupyter Notebook in `visualization/` and run the provided analysis code to generate visualizations.

## ğŸ“Š Example Visualizations
- **Price Distribution:** Compare how prices vary between platforms.
- **Average Prices:** See which platform offers the best deals.
- **Price Trends:** Track price changes over time.

## ğŸ›  Technologies Used
- **Python** ğŸ
- **Selenium & Requests** ğŸŒ (for web scraping)
- **Pandas & NumPy** ğŸ“Š (for data processing)
- **Seaborn & Matplotlib** ğŸ“ˆ (for visualizations)
- **Threading** âš¡ (for parallel execution)

---
ğŸ“ **Feel free to suggest improvements or contribute to the project!** ğŸš€
